{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_Scraping_broadway.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxn589M816xw"
      },
      "outputs": [],
      "source": [
        "import requests  ## used for requesting to access the HTML webpage\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import bs4 ## used for web scrapping\n",
        "from bs4 import BeautifulSoup \n",
        "from seaborn import set_style\n",
        "set_style('whitegrid')\n",
        "from time import sleep\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime ## used for working with datetime formats\n",
        "import re\n",
        "start = datetime.datetime.strptime(\"09-06-1985\", \"%d-%m-%Y\")\n",
        "end = datetime.datetime.strptime(\"26-12-1999\", \"%d-%m-%Y\")\n",
        "date_generated = pd.date_range(start, end)\n",
        "\n",
        "d = date_generated[0:-1:7]\n",
        "d2 = []\n",
        "for j in d: \n",
        "  d2.append(str(j.date()))\n",
        "base_url = \"https://www.playbill.com/grosses?week=\"\n",
        "i=0\n",
        "## Making an empty list\n",
        "show_names=[]\n",
        "potential_gross=[]\n",
        "seats_sold=[]\n",
        "previews=[]\n",
        "cap=[]\n",
        "diff=[]\n",
        "diff_cap=[]\n",
        "top_ticket=[]\n",
        "avg_ticket=[]\n",
        "seats_in_theatre=[]\n",
        "theatre_name=[]\n",
        "year = []\n",
        "\n",
        "for e in d2: ## Iteration for every week spanning from 1984-2022\n",
        "    html = requests.get(base_url + e)\n",
        "    soup = BeautifulSoup(html.content, 'html.parser') ##Using Beautiful Soup from bs4 package to read the webpage\n",
        "    table = soup.find('tbody')  ## soup.find searches for the table from webpage\n",
        "    rows = table.find_all('tr') ## searches rows (tr is the HTML code for rows)\n",
        "    for row in rows:\n",
        "        \n",
        "        cols=row.find_all('td')\n",
        "        cols=[x.text.strip() for x in cols]    ## Scrapping values\n",
        "        #print(cols)\n",
        "        year.append(e)\n",
        "        #theatre_name.append(cols[0].split('\\n\\n')[1])\n",
        "        show_names.append(cols[0].split('\\n')[0])\n",
        "        potential_gross.append(cols[1])\n",
        "        diff.append(cols[2])\n",
        "        avg_ticket.append(cols[3].split('\\n')[0])\n",
        "        #top_ticket.append(cols[3].split('\\n')[1])\n",
        "        seats_sold.append(cols[4].split('\\n')[0])\n",
        "        seats_in_theatre.append(cols[4].split('\\n')[1])\n",
        "        previews.append(cols[5].split('\\n')[0])\n",
        "        cap.append(cols[6])\n",
        "        diff_cap.append(cols[7])\n",
        "## Having scrapped all the relevant data, converting the data into a dataframe\n",
        "df = pd.DataFrame({'Year':year,'Show_name':show_names, \n",
        "                   'Potential_Gross':potential_gross,'Difference':diff,\n",
        "                   'Average_ticket':avg_ticket,\n",
        "                   'Seats_Sold':seats_sold,'Seats_in_theater':seats_in_theatre,\n",
        "                   'Previews':previews,'%cap':cap,'diff_cap':diff_cap})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "xkk_VHzV2F-z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "U4AqRhHe2PyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Refining the data to make it use for Analysis\n",
        "df.replace(',','', regex=True, inplace=True)  ## Removing commas into the strings\n",
        "df.replace('%','', regex=True, inplace=True)  ## Removing the % sign into the strings\n",
        "df['Potential_Gross']=df[\"Potential_Gross\"].str.replace('$', '')  ## Removing $ sign \n",
        "df['Difference']=df['Difference'].str.replace('$', '')\n",
        "#df['Top_ticket'] = df['Top_ticket'].str.replace('$', '')\n",
        "df['Average_ticket']=df['Average_ticket'].str.replace('$', '')\n",
        "df[\"Average_ticket\"] = pd.to_numeric(df[\"Average_ticket\"], downcast=\"float\") ## Converting numeric characters of string to float type values \n",
        "#df[\"Difference\"] = pd.to_numeric(df[\"Difference\"], downcast=\"float\")\n",
        "#df[\"Top_ticket\"] = pd.to_numeric(df[\"Top_ticket\"], downcast=\"float\")\n",
        "df[\"Seats_Sold\"] = pd.to_numeric(df[\"Seats_Sold\"], downcast=\"float\")\n",
        "df[\"Seats_in_theater\"] = pd.to_numeric(df[\"Seats_in_theater\"], downcast=\"float\")\n",
        "df[\"Previews\"] = pd.to_numeric(df[\"Previews\"], downcast=\"float\")\n",
        "df[\"%cap\"] = pd.to_numeric(df[\"%cap\"], downcast=\"float\")\n",
        "df[\"diff_cap\"] = pd.to_numeric(df[\"diff_cap\"], downcast=\"float\")\n",
        "df"
      ],
      "metadata": {
        "id": "YrV9ZBWD2X6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['Potential_Gross'])\n",
        "#df['Potential_Gross']=df['Potential_Gross'].split('\\n')[1]\n",
        "df[\"Potential_Gross\"]= df[\"Potential_Gross\"].str.split(\"\\n\", n = 0, expand = True)[1]\n",
        "df[\"Potential_Gross\"] = pd.to_numeric(df[\"Potential_Gross\"], downcast=\"float\")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "y1CUOQCQ2bab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('1985-2022.csv')\n",
        "from google.colab import files\n",
        "files.download(\"1985-2022.csv\")"
      ],
      "metadata": {
        "id": "RQkbV3mW2dLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Eobw4Bwx2e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5b94554f-ed7a-48dd-8cce-e5c055347a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_903636b8-9f89-4204-85f3-89e3606fd16e\", \"1985-1999.csv\", 1288039)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lzwoi18XDx0w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}